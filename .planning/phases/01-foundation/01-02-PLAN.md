---
phase: 01-foundation
plan: "02"
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - src/tools/registry.py
  - src/tools/schemas/search_flights.json
  - src/tools/schemas/web_search.json
  - src/tools/schemas/summarize_sources.json
  - src/subjects/booking_agent.py
  - src/subjects/search_agent.py
  - src/subjects/summary_agent.py
  - src/subjects/run_subjects.py
  - tests/test_subject_failures.py
autonomous: true
must_haves:
  truths:
    - "BookingAgent fails reliably on DD/MM/YYYY date input"
    - "SearchAgent fails reliably on an ambiguous tool-selection scenario"
    - "SummaryAgent produces a reproducible hallucination failure mode"
  artifacts:
    - path: "src/subjects/booking_agent.py"
      provides: "Date-format failure scenario"
    - path: "src/subjects/search_agent.py"
      provides: "Wrong-tool selection failure scenario"
    - path: "src/subjects/summary_agent.py"
      provides: "Hallucination failure scenario"
    - path: "src/subjects/run_subjects.py"
      provides: "CLI runner for all subject scenarios"
  key_links:
    - from: "src/subjects/run_subjects.py"
      to: "src/subjects/*.py"
      via: "scenario dispatch"
      pattern: "run_.*scenario"

---

<objective>
Implement three predictable “test subject” agents plus a small tool registry so failures are deterministic and produce meaningful traces.

Purpose: Provide reliable inputs for the autopsy pipeline (no flaky demos).
Output: Subject agent modules, tool schemas, and a runner.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@/home/ubuntu/workspace/ai-dev-days-hackathon/plans/agent-autopsy.md
@.planning/phases/01-foundation/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add JSON-schema tool registry used by subject scenarios</name>
  <files>
src/tools/__init__.py
src/tools/registry.py
src/tools/schemas/search_flights.json
src/tools/schemas/web_search.json
src/tools/schemas/summarize_sources.json
  </files>
  <action>
- Create `src/tools/registry.py` that:
  - Loads JSON schemas from `src/tools/schemas/*.json`.
  - Validates tool call payloads (tool name + args dict) against the schema.
  - Returns structured results or raises a consistent exception type for validation errors.
- Include three tool schemas:
  - `search_flights` requires `date` in ISO `YYYY-MM-DD` (regex), plus minimal required fields.
  - `web_search` requires a `query` string.
  - `summarize_sources` requires `sources` as a non-empty list of strings.
  </action>
  <verify>
python3 -c "from src.tools.registry import ToolRegistry; r=ToolRegistry(); r.validate('search_flights', {'date':'2026-02-08','from':'NYC','to':'LAX'}); print('ok')"
  </verify>
  <done>
- Tool schemas load and validate correctly
- Invalid payloads raise a stable, catchable error type
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement subject agents + a runner that triggers predictable failures</name>
  <files>
src/subjects/booking_agent.py
src/subjects/search_agent.py
src/subjects/summary_agent.py
src/subjects/run_subjects.py
  </files>
  <action>
- Implement each subject as a small, *deterministic* scenario function that produces a failure on demand:
  - BookingAgent: attempts `search_flights` with `date='15/02/2026'` and should fail schema validation.
  - SearchAgent: given an ambiguous instruction, intentionally selects `summarize_sources` without sources (or selects `web_search` with missing query) and fails validation.
  - SummaryAgent: given a tiny source list, returns a summary containing at least one explicitly false claim and tags it as `hallucinated=true` in the returned object.
- Create `src/subjects/run_subjects.py` CLI that can run `booking`, `search`, `summary` scenarios and prints a machine-parseable JSON blob containing (minimum fields):
   - `subject`, `status`, `input`, `tool_calls` attempted, and the resulting exception or hallucination marker.
   - `status` MUST be one of: `passed` | `failed` | `hallucinated`.
   - For the two validation scenarios, encode the expected failure as JSON (`status='failed'`, plus error metadata). Do NOT rely on process exit codes.
   - CLI MUST exit 0 for all scenarios so automation runners can execute the whole suite deterministically.
   - CLI output contract: write the JSON result to stdout; write any human logs to stderr (so callers can `json.load(sys.stdin)` safely).
 - Do not integrate Cosmos/FailureDetector here; keep subjects pure and callable.
  </action>
  <verify>
 python3 -c "import json,subprocess; p=subprocess.run(['python3','-m','src.subjects.run_subjects','booking'],capture_output=True,text=True); assert p.returncode==0; d=json.loads(p.stdout); assert d['subject']=='booking'; assert d['status']=='failed'; assert 'input' in d and 'tool_calls' in d"
 python3 -c "import json,subprocess; p=subprocess.run(['python3','-m','src.subjects.run_subjects','search'],capture_output=True,text=True); assert p.returncode==0; d=json.loads(p.stdout); assert d['subject']=='search'; assert d['status']=='failed'; assert 'input' in d and 'tool_calls' in d"
 python3 -c "import json,subprocess; p=subprocess.run(['python3','-m','src.subjects.run_subjects','summary'],capture_output=True,text=True); assert p.returncode==0; d=json.loads(p.stdout); assert d['subject']=='summary'; assert d['status']=='hallucinated'; assert d.get('hallucinated') is True"
  </verify>
  <done>
- Each scenario produces its intended failure mode every run
- Runner prints JSON with enough detail to build traces/findings later
- Runner exits 0 even when the scenario reports `status='failed'`
  </done>
</task>

<task type="auto">
  <name>Task 3: Add a single smoke test asserting failure determinism</name>
  <files>
tests/test_subject_failures.py
  </files>
  <action>
- Add `tests/test_subject_failures.py` that runs each scenario function directly (no network calls) and asserts:
  - Booking/Search raise the expected validation exception type.
  - Summary returns an object with `hallucinated == True` and includes the known false claim string.
- Keep tests fast and deterministic; no Foundry/Azure calls.
  </action>
  <verify>
python3 -m pytest -q
  </verify>
  <done>
- Tests pass and enforce that failures remain predictable
  </done>
</task>

</tasks>

<verification>
- `python3 -m pytest -q` passes
- Running `python3 -m src.subjects.run_subjects booking` exits 0 and prints JSON with `status='failed'`
- Running `python3 -m src.subjects.run_subjects search` exits 0 and prints JSON with `status='failed'`
- Running `python3 -m src.subjects.run_subjects summary` exits 0 and prints JSON with `status='hallucinated'` and `hallucinated=true`
</verification>

<success_criteria>
- All three subject failures are reproducible and generate structured output
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-02-SUMMARY.md`
</output>
